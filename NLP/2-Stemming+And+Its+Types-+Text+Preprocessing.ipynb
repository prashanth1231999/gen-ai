{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2026.1.15-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\prash\\.conda\\envs\\gen-ai\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.3 MB/s  0:00:00\n",
      "Downloading regex-2026.1.15-cp310-cp310-win_amd64.whl (277 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   -------- ------------------------------- 1/5 [regex]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ------------------------ --------------- 3/5 [click]\n",
      "   ------------------------ --------------- 3/5 [click]\n",
      "   ------------------------ --------------- 3/5 [click]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   ---------------------------------------- 5/5 [nltk]\n",
      "\n",
      "Successfully installed click-8.3.1 joblib-1.5.3 nltk-3.9.2 regex-2026.1.15 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\prash\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\prash\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\prash\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelscope 1.30.0 requires filelock, which is not installed.\n",
      "paddleocr 2.7.0.2 requires cython, which is not installed.\n",
      "paddleocr 2.7.0.2 requires fonttools>=4.24.0, which is not installed.\n",
      "paddleocr 2.7.0.2 requires lxml, which is not installed.\n",
      "paddleocr 2.7.0.2 requires openpyxl, which is not installed.\n",
      "paddleocr 2.7.0.2 requires Pillow, which is not installed.\n",
      "paddleocr 2.7.0.2 requires scikit-image, which is not installed.\n",
      "paddlex 3.2.1 requires chardet, which is not installed.\n",
      "paddlex 3.2.1 requires filelock, which is not installed.\n",
      "paddlex 3.2.1 requires huggingface_hub, which is not installed.\n",
      "paddlex 3.2.1 requires pillow, which is not installed.\n",
      "paddlex 3.2.1 requires ruamel.yaml, which is not installed.\n",
      "paddlex 3.2.1 requires ujson, which is not installed.\n",
      "spacy 3.5.3 requires smart-open<7.0.0,>=5.2.1, which is not installed.\n",
      "streamlit 1.33.0 requires pillow<11,>=7.1.0, which is not installed.\n",
      "streamlit 1.33.0 requires toml<2,>=0.10.1, which is not installed.\n",
      "streamlit 1.33.0 requires watchdog>=2.1.5; platform_system != \"Darwin\", which is not installed.\n",
      "paddlex 3.2.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
      "spacy 3.5.3 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.12.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\prash\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\prash\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification Problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are using PorterStemmer and output can be enhanced using other stemming techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('^ing|s$|e$|able$', min=4)   # :param min: The minimum length of string to stem  \n",
    "# ^ing -> ends with ing will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eating'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer=RegexpStemmer('ing$|s$|e$|able$', min=4)   # :param min: The minimum length of string to stem  \n",
    "# ing$ -> ends with ing will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball Stemmer\n",
    " It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballsstemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+snowballsstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem(\"fairly\"),snowballsstemmer.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballsstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### stemming recommended for text classification problems\n",
    "### Lemmatization recommended for chat bot use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
